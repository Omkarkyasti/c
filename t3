gender

ï‚·Create a .CSV file(data.csv) and add the following data


1.
hduser@ubuntu:~/Documents$ touch mapper.py
2. 
hduser@ubuntu:~/Documents$ cat mapper.py 
3. 
hduser@ubuntu:~/Documents$ nano mapper.py 
#!/usr/bin/python
import sys
# input comes from STDIN (standard input)
for line in sys.stdin:
    line = line.strip()
    line = line.split(",")
    if len(line) >=2:
        gender = line[1]
        age = line[2]
        print '%s\t%s' % (gender, age)




4.
hduser@ubuntu:~/Documents$ cat data.csv | python mapper.py 

5 .
hduser@ubuntu:~/Documents$ touch reducer.py
6.
Hduser@ubuntu:~/Documents$ cat reducer.py 
7.
hd.user@ubuntu:~/Documents$ nano reducer.py 
#!/usr/bin/python
#Reducer.py
import sys
gender_age = {}
#Partitoner
for line in sys.stdin:
    line = line.strip()
    gender, age = line.split('\t')
    if gender in gender_age:
        gender_age[gender].append(int(age))
    else:
        gender_age[gender] = []
        gender_age[gender].append(int(age))
for gender in gender_age.keys():
    ave_age = sum(gender_age[gender])*1.0 / len(gender_age[gender])
    print '%s\t%s'% (gender, ave_age)

12.
hduser@ubuntu:~/Documents$ cat  data.csv| python mapper.py  | python reducer.py 

13.
hduser@ubuntu:~/Documents$,star-all.sh
14.
hduser@ubuntu:~/Documents$ jps

15. 
hduser@ubuntu:~/Documents$ hdfs dfs -mkdir /data_age
16.
hduser@ubuntu:~/Documents$ hdfs dfs -copyFromLocal /home/hduser/Documents/ data.csv  /data_age

17.
hduser@ubuntu:~/Documents$ hdfs dfs -ls /
18.
hduser@ubuntu:~/Documents$ hdfs dfs -ls / data_age

19.
hduser@ubuntu:~/Documents$ chmod 777 mapper.py reducer.py 
20.
hduser@ubuntu:~/Documents$ ls -l
21.
hduser@ubuntu:~/Documents$ hadoop jar /home/hduser/Documents/hadoop-streaming-2.7.3.jar \
> -input /data_age/ data.csv \
> -output /data_age/output \
> -mapper /home/hduser/Documents/mapper.py \
> -reducer /home/hduser/Documents/reducer.py 
hduser@ubuntu:~/Documents$
